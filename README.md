<div align="center">

## **Qiming Bao**

<p align="center">

[![LinkedIn](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/qiming-bill-bao-773757166/)](https://www.linkedin.com/in/qiming-bill-bao-773757166/)&nbsp;&nbsp;
[![Gmail](https://img.shields.io/badge/-Gmail-red?style=flat-square&logo=Gmail&logoColor=white&link=mailto:qiming.bao@auckland.ac.nz)](mailto:qiming.bao@auckland.ac.nz)&nbsp;&nbsp;
[![Google Scholar](https://img.shields.io/badge/-Google%20Scholar-blue?style=flat-square&logo=Google%20Scholar&logoColor=white&link=https://scholar.google.com/citations?user=t-PqsgcAAAAJ)](https://scholar.google.com/citations?user=t-PqsgcAAAAJ&hl=en)&nbsp;&nbsp;
[![Twitter](https://img.shields.io/badge/-Twitter-blue?style=flat-square&logo=Twitter&logoColor=white&link=https://twitter.com/qiming_bao)](https://twitter.com/qiming_bao)
</p>
</div>



Qiming Bao is a Ph.D. Candidate at the <A href="https://www.ai.ac.nz/sail/"><FONT face="Bitstream Vera Sans">Strong AI Lab</FONT></A> & <A href="https://www.liuailab.org/"><FONT face="Bitstream Vera Sans">LIU AI Lab</FONT></A>, School of Computer Science, University of Auckland, New Zealand. His supervisors are Professor <A href="https://profiles.auckland.ac.nz/m-witbrock"><FONT face="Bitstream Vera Sans">Michael Witbrock</FONT></A> and Dr. <A href="https://profiles.auckland.ac.nz/jiamou-liu"><FONT face="Bitstream Vera Sans">Jiamou Liu</FONT></A>. His research interests include natural language processing and reasoning. He has over three years of research and development experience, and has published several papers in top conferences in the fields of AI/NLP/Reasoning, including **AAAI/EAAI**, **ICLR**, **ACL**, **EACL**, **LLM@IJCAI**, and **IJCLR-NeSy**. His model named **AMR-LDA** has achieved the **#1** ranking on one of the most challenged logical reasoning reading comprehension leaderboards (<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">ReClor</FONT></A>) up to now, and two of his logical reasoning datasets called <A href="https://github.com/Strong-AI-Lab/PARARULE-Plus"><FONT face="Bitstream Vera Sans">PARARULE-Plus</FONT></A> and <A href="https://github.com/Strong-AI-Lab/AbductionRules"><FONT face="Bitstream Vera Sans">AbductionRules</FONT></A> have been collected by <A href="https://www.logitorch.ai/"><FONT face="Bitstream Vera Sans">LogiTorch</FONT></A>, <A href="https://github.com/FreedomIntelligence/ReasoningNLP"><FONT face="Bitstream Vera Sans">ReasoningNLP</FONT></A>, <A href="https://github.com/zjunlp/Prompt4ReasoningPapers"><FONT face="Bitstream Vera Sans">Prompt4ReasoningPapers</FONT></A> and <A href="https://github.com/openai/evals/pull/651"><FONT face="Bitstream Vera Sans">OpenAI/Evals</FONT></A>. Qiming has given public guest talks at <A href="https://youtu.be/nfNbSZPY4EU"><FONT face="Bitstream Vera Sans">Microsoft Research Asia</FONT></A>, <A href="https://youtu.be/0ZkayBD3WVY"><FONT face="Bitstream Vera Sans">Samsung AI Center Cambridge UK</FONT></A>, and <A href="https://youtu.be/ZzCpq5gXQto"><FONT face="Bitstream Vera Sans">IEEE Vehicular Technology Society</FONT></A> on his main research topic, "Natural Language Processing and Reasoning".

Qiming is an AI engineer (Part-time) at <A href="https://xtracta.com/"><FONT face="Bitstream Vera Sans">Xtracta</FONT></A> in Auckland, New Zealand, where he he investigated and implemented alternative attention mechanisms to extend the effective sequence length in multi-modal document processing models such as LayoutXLM, LayoutLMv3, and ERNIE-LayoutX. He replicated the multi-task, multimodal pre-training code for LayoutLMv3, which Microsoft did not open source, including masked language modeling, masked image modeling, and word-patch alignment. He successfully applied for the Research & Development Tax Incentive (RDTI) grants from Callaghan Innovation (New Zealand's Innovation Agency) for both 2022 and 2023, each offering a tax credit equal to 15% of eligible R&D expenditure. This credit can be utilised to reduce the income tax payable by the company. Prior to this role, he worked as a research and development engineer in <A href="https://www.aiit.org.cn/p_enPage"><FONT face="Bitstream Vera Sans">AIIT</FONT></A> at Peking University, where he focused on automatic abstract generation and GPT-2 based dialog chatbot development. Qiming also has a great deal of teaching experience, having worked as a teaching assistant for three years. He earned a Bachelor of Science (Honours) in Computer Science (First Class) from the University of Auckland and completed a Summer Research Internship with Scholarship in <A href="https://precisiondrivenhealth.com/"><FONT face="Bitstream Vera Sans">Precision Driven Health</FONT></A>. In addition, he was selected as one of ten students to participate in the <A href="https://precisiondrivenhealth.com/an-online-system-for-answering-medical-questions/"><FONT face="Bitstream Vera Sans">Summer Research Program</FONT></A> funded by Precision Driven Health, where the main topic was developing a Medical Chatbot based on Deep Learning and Knowledge Graph.

<!--**I am open to looking for a full-time job opportunity related to Post-doc Researcher, Machine Learning/AI Engineer. I am passionate and skilled in data-driven projects, especially on Natural Language Processing, with more than three years of work and project experience. I can bring state-of-the-art ideas and technology to your lab/company.** -->

<h4 align="center">Papers/Projects</h4>

- [20 September 2023] Our paper (**Qiming Bao**, Juho Leinonen, Alex Peng, Wanjun Zhong, Timothy Pistotti, Alice Huang, Paul Denny, Michael Witbrock and Jiamou Liu) "Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models" [<A href="http://arxiv.org/abs/2309.10444"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Explanation-Generation"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].<br />

- [24 June 2023] Our paper (**Qiming Bao**, Gaël Gendron, Alex Peng, Wanjun Zhong, Neset Tan, Yang Chen, Michael Witbrock, Jiamou Liu) "A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks" has been accepted by <A href="https://bigmodel.ai/llm-ijcai23"><FONT face="Bitstream Vera Sans">LLM@IJCAI'23</FONT></A> [<A href="https://arxiv.org/abs/2310.09430"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].

- [24 June 2023] Our paper (**Qiming Bao**, Alex Peng, Zhenyun Deng, Wanjun Zhong, Gaël Gendron, Timothy Pistotti, Neşet Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock and Jiamou Liu) "Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation" has been accepted by <A href="https://bigmodel.ai/llm-ijcai23"><FONT face="Bitstream Vera Sans">LLM@IJCAI'23</FONT></A> [<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">#1 on the ReClor Leaderboard</FONT></A>] [<A href="https://arxiv.org/abs/2305.12599v2"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].

- [31 May 2023] Our paper (Gaël Gendron, **Qiming Bao**, Michael Witbrock, Gillian Dobbie) "Large Language Models Are Not Abstract Reasoners" [<A href="https://arxiv.org/abs/2305.19555"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning"><FONT face="Bitstream Vera Sans">Source code and evaluation platform</FONT></A>].<br />

- [21 May 2023] Our paper (**Qiming Bao**, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock, Jiamou Liu) "Contrastive Learning with Logic-driven Data Augmentation for Logical Reasoning over Text" [<A href="https://arxiv.org/abs/2305.12599"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning"><FONT face="Bitstream Vera Sans">Source code</FONT></A>] [<A href="https://huggingface.co/qbao775/AMR-LE-DeBERTa-V2-XXLarge-Contraposition"><FONT face="Bitstream Vera Sans">Model weights</FONT></A>] [<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">Leaderboard</FONT></A>].<br />

- [10 April 2023] Our paper (Qianqian Qi, **Qiming Bao***, Alex Yuxuan Peng, Jiamou Liu, Michael Witbrock) "A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge" has been accepted by <A href="https://openreview.net/group?id=ICLR.cc/2023/TinyPapers"><FONT face="Bitstream Vera Sans">ICLR-23 TinyPapers</FONT></A> [<A href="https://openreview.net/forum?id=hli7A0ioiS_"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>].<br />
  
- [01 March 2023] Our paper (Neset Tan, Alex Peng, Joshua Bensemann, **Qiming Bao**, Tim Hartill, Mark Gahegan, and Michael Witbrock) "Input-length-shortening and text generation via attention values" has been accepted by <A href="https://www.emc2-ai.org/aaai-23"><FONT face="Bitstream Vera Sans">AAAI-EMC^2-23</FONT></A> [<A href="https://arxiv.org/abs/2303.07585"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>].<br />
    
- [23 January 2023] Our paper (Neset Ozkan TAN, Trung Nguyen, Josh Bensemann, Alex Peng, **Qiming Bao**, Yang Chen, Mark Gahegan and Michael Witcbrock) "Multi2Claim: Generating Scientific Claims from Multi-Choice Questions for Scientific Fact-Checking" has been accepted and published by <A href="https://2023.eacl.org/"><FONT face="Bitstream Vera Sans">EACL-23</FONT></A> [<A href="https://aclanthology.org/2023.eacl-main.194/"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>]. <br />
    
- [16 July 2022] Our paper (**Qiming Bao**, Alex Peng, Tim Hartill, Neset Tan, Zhenyun Deng, Michael Witbrock, Jiamou Liu) "Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation" has been accepted for presentation to the <A href="http://ceur-ws.org/Vol-3212/"><FONT face="Bitstream Vera Sans">2nd International Joint Conference on Learning & Reasoning and 16th International Workshop on Neural-Symbolic Learning and Reasoning (IJCLR-NeSy-22)</FONT></A> [<A href="https://ceur-ws.org/Vol-3212/paper15.pdf"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language"><FONT face="Bitstream Vera Sans">Source code and dataset</FONT></A>] [<A href="http://ilp.doc.ic.ac.uk/ijclr22_videos/NeSy%20Session%205%20-%20Thursday%2029th%20-%2014_40%20-%2015_50%20(BST)%20includes%20NeSy%20Invited%20Talk%20William%20Cohen.mp4"><FONT face="Bitstream Vera Sans">Presentation recording</FONT></A>]. <br />
    
- [24 February 2022] Our paper (Nathan Young, **Qiming Bao**, Joshua Ljudo Bensemann, Michael J. Witbrock) "AbductionRules: Training Transformers to Explain Unexpected Inputs" has been accpeted for publication in the Findings of <A href="https://www.2022.aclweb.org/"><FONT face="Bitstream Vera Sans">60th Annual Meeting of the Association for Computational Linguistics (ACL-22)</FONT></A> [<A href="https://aclanthology.org/2022.findings-acl.19/"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/AbductionRules"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].<br />
  
- [13 November 2021] Our paper (Lin Ni, **Qiming Bao**, Xiaoxuan Li, Qianqian Qi, Paul Denny, Jim Warren, Michael Witbrock and Jiamou Liu) "DeepQR: Neural-based Quality Ratings for Learnersourced Multiple-Choice Questions" has been accepted for publication in the Long Paper of <A href="https://aaai.org/conference/aaai/aaai-22/eaai-22/"><FONT face="Bitstream Vera Sans">Twelfth AAAI Symposium on Educational Advances in Artificial Intelligence (AAAI/EAAI-22)</FONT></A> [<A href="https://ojs.aaai.org/index.php/AAAI/article/view/21562"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>]. <br />

- [04 February 2020] Our paper (**Qiming Bao**, Lin Ni, Jiamou Liu) "HHH: An Online Medical Chatbot System based on Knowledge Graph and Hierarchical Bi-Directional Attention" has been accepted for publication in the Long Paper of <A href="https://acsw.core.edu.au/2020-acsw-home"><FONT face="Bitstream Vera Sans">Australasian Computer Science Week (ACSW-20)</FONT></A> [<A href="https://arxiv.org/abs/2002.03140"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/14H034160212/HHH-An-Online-Question-Answering-System-for-Medical-Questions"><FONT face="Bitstream Vera Sans">Source code</FONT></A>] [<A href="https://www.youtube.com/redirect?event=comments&redir_token=QUFFLUhqbWtqVHRmbzdQYVJFSW9odl9qZF9CWTdxUXdvQXxBQ3Jtc0ttQjRBdktkOFQ1enpvUGk1X0ZLT0hIb3g5WnhZWjVyVjFiVUQ1STdTeW9pMXdpYlJWSk9xeVA0Y01Qbm85bkQtRWxjdlk5TWdfY2I0OFNIazBhRkFoNEN6YmdjYTFaVnh3Ynkyel9LQjNhbkZ4WGxwQQ&q=https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F15BfDM07IdUJiqONTAXAhIk3Y8a6oWn_2%2Fedit%3Fusp%3Dsharing%26ouid%3D116744487318855501460%26rtpof%3Dtrue%26sd%3Dtrue&stzid=UgxhkQ3dcho0vzjqWIV4AaABAg"><FONT face="Bitstream Vera Sans">Presentation slide</FONT></A>] [<A href="https://youtu.be/zTK3zZtxHs4"><FONT face="Bitstream Vera Sans">Recording</FONT></A>]. <br />
<h4 align="center">News</h4>

- [04 October 2023] Our AMR-LDA prompt augmentation with GPT-4 achieves **#1** on the ReClor: A Logical Reasoning Reading Comprehension Leaderboard [<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">Leaderboard</FONT></A>] [<A href="https://arxiv.org/abs/2305.12599v2"><FONT face="Bitstream Vera Sans">Paper link</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning"><FONT face="Bitstream Vera Sans">Source code</FONT></A>].

- [13 April 2023] Our two pull requests to <A href="https://github.com/openai/evals"><FONT face="Bitstream Vera Sans">OpenAI/Evals</FONT></A> have been merged 
        [<A href="https://github.com/openai/evals/pull/648"><FONT face="Bitstream Vera Sans">A Group of more Challenge Logical Reasoning Datasets</FONT></A>]
	[<A href="https://github.com/openai/evals/pull/651"><FONT face="Bitstream Vera Sans">A Larger Deep Multi-Step Deductive Reasoning Dataset</FONT></A>]. <br />

- [18 January 2023] We tested and listed the cases that GPT-3, ChatGPT-3.5 and GPT-4 failed, including multi-step reasoning, logical equivalence, and logical reasoning to the spreadsheet created by Gary Marcus and Ernest Davis at NYU.
        [<A href="https://twitter.com/qiming_bao/status/1615311194931490818"><FONT face="Bitstream Vera Sans">Tweets Link for Multi-Step Reasoning and Logical Equivalence</FONT></A>] [<A href="https://twitter.com/qiming_bao/status/1625688954514333698"><FONT face="Bitstream Vera Sans">Tweets Link for Logical Reasoning Reading Comprehension</FONT></A>] [<A href="https://twitter.com/qiming_bao/status/1642067379319607296"><FONT face="Bitstream Vera Sans">Tweets Link for GPT-4 fails on Logical Reasoning Reading Comprehension</FONT></A>] [<A href="https://docs.google.com/spreadsheets/d/1kDSERnROv5FgHbVN8z_bXH9gak2IXRtoqz0nwhrviCw/edit#gid=1302320625"><FONT face="Bitstream Vera Sans">Spreadsheet Link</FONT></A>] [<A href="https://researchrabbit.typeform.com/llmerrors?typeform-source=www.linkedin.com"><FONT face="Bitstream Vera Sans">Submit your cases</FONT></A>]. <br />

- [07 December 2022] Qiming Bao achieved **#2** (Submission name: AMR-LDA-Ensemble (AMR-LDA-Deberta-v2-xxlarge(Ense)) and #4 (Submission name: AMR-LDA (DeBERTa-v2-xxlarge-AMR-LDA-Cont)) on the ReClor: A Logical Reasoning Reading Comprehension Leaderboard [<A href="https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347"><FONT face="Bitstream Vera Sans">Leaderboard</FONT></A>] [<A href="https://arxiv.org/abs/2305.12599"><FONT face="Bitstream Vera Sans">Paper</FONT></A>] [<A href="https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning"><FONT face="Bitstream Vera Sans">Source code</FONT></A>] [<A href="https://huggingface.co/qbao775/AMR-LE-DeBERTa-V2-XXLarge-Contraposition"><FONT face="Bitstream Vera Sans">Model weights</FONT></A>]. <br />

- [17 November 2022] Our <A href="https://github.com/Strong-AI-Lab/PARARULE-Plus"><FONT face="Bitstream Vera Sans">PARARULE Plus</FONT></A> (Multi-step deductive reasoning) and <A href="https://github.com/Strong-AI-Lab/AbductionRules"><FONT face="Bitstream Vera Sans">AbductionRules</FONT></A> (Abductive reasoning) datasets are collected as part of <A href="https://www.logitorch.ai/"><FONT face="Bitstream Vera Sans">LogiTorch.ai</FONT></A>. <br/>

- [09 January 2022] One of the contributers to an open source tool for simplifying bibtex called "SimBiber" [<A href="https://github.com/MLNLP-World/SimBiber"><FONT face="Bitstream Vera Sans">GitHub link</FONT></A>]. <br />


<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=14H034160212&PAT_1=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&show_icons=true&theme=radical" alt="Qiming Bao's GitHub stats"/>
</p>

<h4 align="center">Wekatime States(Since April 24, 2023)</h4>
<div>
<p align = "center"><img src="https://github-readme-stats.vercel.app/api/wakatime?username=14H034160212&langs_count=4&show_icons=true&locale=en&theme=nord&layout=compact&hide_title=true&hide_border=true" alt="14H034160212" /></p>
</div>
